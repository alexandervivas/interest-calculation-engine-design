# Core Interest Engine (CIE)

**A High-Throughput, Deterministic Financial Ledger Sidecar.**

> **Status:** Active Development
> **Docs:** [Full Documentation](./docs/00-home.md) | [Architecture](./docs/architecture/) | [ADRs](./docs/decisions/)

---

## 1. System Guarantees & Reliability Strategies

This system processes massive financial volumes (100M+ accounts/day). To ensure correctness, we rely on specific architectural patterns rather than hoping for "happy path" execution.

### 1.1 Avoiding Double-Posting (Idempotency)
**Objective:** If the Posting Service crashes after sending a request but before recording success, retries must not result in duplicate money.

**Approach:** **Deterministic Idempotency Keys**.
Every interest posting command generated by this engine includes a unique `idempotency_key` derived from the domain data, not a random UUID.

$$Key = \text{Hash}(\text{AccountID} + \text{ValueDate} + \text{Type})$$

* **Example:** `acc_888_2024-01-01_INT_ACCRUAL`
* **Mechanism:**
    1.  Engine calculates interest.
    2.  Engine generates the Key.
    3.  Engine sends Command to Ledger with Key.
    4.  **Ledger Contract:** The Ledger (downstream) guarantees uniqueness on this key. If it receives a second request with the same Key, it acknowledges success (HTTP 200 / Ack) but **does not** book a new transaction.

### 1.2 Ensuring Exactly-Once Processing
**Objective:** Every account must be processed exactly once per day. No skips, no duplicates.

**Approach:** **Kafka Transactions (`read_committed`) + Partition Stickiness.**

1.  **Read-Process-Write Atomicity:** We use the Kafka Transactional API.
    * We consume a batch of transactions.
    * We update the internal state (DB).
    * We produce the `InterestCalculated` event.
    * We commit the consumer offset.
    * *All of the above happen in a single atomic transaction.* If the process dies at step 3, the offset is never committed, and the next pod replays the batch.
2.  **Isolation:** Consumers are configured with `isolation.level=read_committed`. Downstream consumers will not see our output messages unless the transaction successfully commits.

### 1.3 Recovery After Partial Failures
**Objective:** If a Kubernetes Pod crashes while processing partition 42 (containing 100k accounts), the system must recover automatically without manual intervention.

**Approach:** **Checkpointing & Offset Replay.**

* **Scenario:** Pod A crashes after processing 50% of a batch.
* **Recovery:**
    1.  Kubernetes detects crash, spins up Pod B.
    2.  Kafka Rebalance assigns Partition 42 to Pod B.
    3.  Pod B reads the last *committed* offset (which points to the start of the crashed batch).
    4.  Pod B re-processes the batch.
    5.  **Safety:** Because of **Idempotency** (Section 1.1) and **Upsert Semantics** in our SQL (`INSERT ... ON CONFLICT DO UPDATE`), re-processing the first 50% is a harmless "No-Op".

### 1.4 Safely Re-Running Computations (The "Oops" Scenario)
**Objective:** We discovered a bug in the math *after* posting interest for January. We need to fix it.

**Approach:** **Delta Adjustments (Forward Correction).**
We never "Rewind and Overwrite" the past. We "Replay and Adjust."

1.  **The Fix:** Deploy the code fix / configuration change.
2.  **The Trigger:** Admin issues a `ReplayCommand` for the affected date range.
3.  **The Logic:**
    * System re-calculates interest using the *new* logic.
    * System compares `New_Result` vs `Stored_Audit_Log` (what we actually paid).
    * System calculates `Delta = New - Old`.
    * System posts a **new** transaction: `Type: ADJUSTMENT`, `Amount: Delta`.
4.  **Result:** The customer's balance is corrected, and the audit trail shows *why* (Original + Adjustment).

---

## 2. Auditability & Traceability

**Objective:** A regulator or customer asks, *"Why was the interest $0.45 on Jan 14th?"*

**Approach:** **The Calculation Trace.**
We do not just store the result; we store the *equation*.

### 2.1 The Trace Record
For every accrual, we persist a trace JSON in the `audit_log` (Postgres/Timescale):

```json
{
  "trace_id": "tx_999",
  "account_id": "acc_123",
  "date": "2024-01-14",
  "inputs": {
    "eod_balance": 15000000,  // $15.00
    "effective_rate": 0.0300, // 3.00%
    "tier_applied": "TIER_1_SILVER",
    "day_count": 365
  },
  "formula": "balance * rate / day_count",
  "math_debug": "15.00 * 0.03 / 365 = 0.001232...",
  "result_micros": 1232
}
````

### 2.2 Reconstruction
To reconstruct the state without trusting the log:
1.  **Fetch Input:** Query the `DailyBalance` table for Jan 14th (Immutable Snapshot).
2.  **Fetch Config:** Query the `ProductConfig` table for the version active on Jan 14th.
3.  **Execute:** Run the current `InterestCalculator` class with these inputs.
4.  **Verify:** Assert that `Reconstructed_Value == Logged_Value`.

---

## 3. Technology Stack

| Component | Technology | Purpose |
| :--- | :--- | :--- |
| **Language** | Kotlin (JVM 21) | Business Logic & Math |
| **Messaging** | Kafka + Avro | Event Stream & Contracts |
| **Storage** | PostgreSQL 16 | Configuration & Audit Logs |
| **State** | Apache Pinot / RocksDB | fast "Point-in-Time" Balance lookups |
| **Orchestration** | Kubernetes + KEDA | Autoscaling based on lag |

---

## 4. Developer Guide

### Prerequisites
* Docker & Docker Compose
* JDK 21+
* Make

### Getting Started
```bash
# 1. Start Infrastructure (Kafka, Postgres, Schema Registry)
make infra-up

# 2. Run Database Migrations
make migrate

# 3. Run Tests (Unit + Integration)
make test

# 4. Start the Application
make run
````

*For detailed architectural decisions, see the [`/docs`](./docs) folder.*

---

## 5. License

This project is proprietary software belonging to **[Bank Name] Core Ledger Team**.
Unauthorized copying of this file, via any medium, is strictly prohibited.

* **Maintainers:** Core Ledger Team
* **Copyright:** Â© 2024 [Bank Name]